{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1540d719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèè Real DLS vs Your Model Comparison\n",
      "============================================================\n",
      "üöÄ Starting comprehensive comparison with real DLS...\n",
      "‚úÖ Model loaded successfully on mps\n",
      "üìÅ Found 2185 sequence files\n",
      "üîÑ Processing matches for real DLS comparison...\n",
      "‚úÖ Successfully processed 0 matches\n",
      "‚ùå No successful predictions made\n",
      "‚ùå Comparison failed. Please check your data and model files.\n",
      "\n",
      "======================================================================\n",
      "üèè Real DLS Comparison Analysis Complete!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# 03_debug_dls_comparison.ipynb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import json\n",
    "import os\n",
    "from glob import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"üèè DEBUG: Real DLS vs Your Model Comparison\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Same DLS resource table as before\n",
    "DLS_RESOURCE_TABLE = {\n",
    "    20: {0: 100.0, 1: 93.4, 2: 85.1, 3: 74.9, 4: 62.7, 5: 49.0, 6: 34.9, 7: 22.6, 8: 12.2, 9: 4.2},\n",
    "    19: {0: 96.4, 1: 90.3, 2: 82.4, 3: 72.8, 4: 61.1, 5: 47.9, 6: 34.2, 7: 22.2, 8: 12.0, 9: 4.1},\n",
    "    18: {0: 92.3, 1: 86.7, 2: 79.1, 3: 70.1, 4: 59.1, 5: 46.4, 6: 33.2, 7: 21.6, 8: 11.7, 9: 4.0},\n",
    "    17: {0: 87.5, 1: 82.4, 2: 75.1, 3: 66.9, 4: 56.7, 5: 44.7, 6: 32.0, 7: 20.8, 8: 11.3, 9: 3.9},\n",
    "    16: {0: 82.1, 1: 77.8, 2: 70.7, 3: 63.2, 4: 54.0, 5: 42.7, 6: 30.6, 7: 20.0, 8: 10.8, 9: 3.7},\n",
    "    15: {0: 76.1, 1: 72.6, 2: 65.8, 3: 59.0, 4: 50.8, 5: 40.2, 6: 28.9, 7: 18.9, 8: 10.2, 9: 3.5},\n",
    "    14: {0: 69.6, 1: 66.9, 2: 60.5, 3: 54.4, 4: 47.4, 5: 37.6, 6: 27.0, 7: 17.7, 8: 9.6, 9: 3.3},\n",
    "    13: {0: 62.7, 1: 60.7, 2: 54.8, 3: 49.4, 4: 43.6, 5: 34.6, 6: 24.9, 7: 16.4, 8: 8.9, 9: 3.0},\n",
    "    12: {0: 55.6, 1: 54.1, 2: 48.8, 3: 44.2, 4: 39.4, 5: 31.4, 6: 22.6, 7: 14.9, 8: 8.1, 9: 2.8},\n",
    "    11: {0: 48.3, 1: 47.4, 2: 42.6, 3: 38.6, 4: 34.8, 5: 27.8, 6: 20.1, 7: 13.3, 8: 7.2, 9: 2.5},\n",
    "    10: {0: 40.9, 1: 40.5, 2: 36.4, 3: 33.0, 4: 30.0, 5: 24.1, 6: 17.5, 7: 11.6, 8: 6.3, 9: 2.2},\n",
    "    9: {0: 33.6, 1: 33.6, 2: 30.3, 3: 27.5, 4: 25.2, 5: 20.3, 6: 14.8, 7: 9.8, 8: 5.3, 9: 1.8},\n",
    "    8: {0: 26.5, 1: 26.8, 2: 24.3, 3: 22.2, 4: 20.5, 5: 16.6, 6: 12.1, 7: 8.0, 8: 4.3, 9: 1.5},\n",
    "    7: {0: 19.8, 1: 20.3, 2: 18.6, 3: 17.1, 4: 15.9, 5: 12.9, 6: 9.4, 7: 6.2, 8: 3.4, 9: 1.2},\n",
    "    6: {0: 13.6, 1: 14.2, 2: 13.1, 3: 12.2, 4: 11.4, 5: 9.3, 6: 6.8, 7: 4.5, 8: 2.4, 9: 0.8},\n",
    "    5: {0: 8.1, 1: 8.8, 2: 8.2, 3: 7.7, 4: 7.3, 5: 6.0, 6: 4.4, 7: 2.9, 8: 1.6, 9: 0.5},\n",
    "    4: {0: 3.8, 1: 4.3, 2: 4.1, 3: 3.9, 4: 3.7, 5: 3.1, 6: 2.3, 7: 1.5, 8: 0.8, 9: 0.3},\n",
    "    3: {0: 1.4, 1: 1.7, 2: 1.7, 3: 1.6, 4: 1.6, 5: 1.3, 6: 1.0, 7: 0.7, 8: 0.4, 9: 0.1},\n",
    "    2: {0: 0.3, 1: 0.4, 2: 0.4, 3: 0.4, 4: 0.4, 5: 0.3, 6: 0.3, 7: 0.2, 8: 0.1, 9: 0.0},\n",
    "    1: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0},\n",
    "    0: {0: 0.0, 1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0}\n",
    "}\n",
    "\n",
    "def get_dls_resource(overs_remaining, wickets_lost):\n",
    "    \"\"\"Get DLS resource percentage from official tables\"\"\"\n",
    "    overs_remaining = max(0, min(20, int(overs_remaining)))\n",
    "    wickets_lost = max(0, min(9, int(wickets_lost)))\n",
    "    \n",
    "    if overs_remaining in DLS_RESOURCE_TABLE:\n",
    "        return DLS_RESOURCE_TABLE[overs_remaining].get(wickets_lost, 0.0)\n",
    "    return 0.0\n",
    "\n",
    "def calculate_real_dls_target(team1_score, team1_resources, team2_resources):\n",
    "    \"\"\"Calculate real DLS target using official methodology\"\"\"\n",
    "    if team2_resources >= team1_resources:\n",
    "        return team1_score\n",
    "    else:\n",
    "        par_score = team1_score * (team2_resources / team1_resources)\n",
    "        return par_score\n",
    "\n",
    "# Load model architecture (same as before)\n",
    "class CricketRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=256, num_layers=3, dropout=0.3):\n",
    "        super(CricketRNN, self).__init__()\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            batch_first=True,\n",
    "            bidirectional=False\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size // 2)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size // 2)\n",
    "        self.fc2 = nn.Linear(hidden_size // 2, hidden_size // 4)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_size // 4)\n",
    "        self.fc3 = nn.Linear(hidden_size // 4, 1)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        last_output = lstm_out[:, -1, :]\n",
    "        \n",
    "        out = self.fc1(last_output)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = self.fc2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        out = self.fc3(out)\n",
    "        return out.squeeze()\n",
    "\n",
    "def load_trained_model():\n",
    "    \"\"\"Load the trained RNN model\"\"\"\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    \n",
    "    model_path = '../data/processed/best_rnn_model_enhanced.pth'\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model file not found: {model_path}\")\n",
    "    \n",
    "    checkpoint = torch.load(model_path, map_location=device)\n",
    "    input_size = 13\n",
    "    \n",
    "    model = CricketRNN(input_size=input_size)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    feature_mean = checkpoint.get('feature_mean', torch.zeros(input_size))\n",
    "    feature_std = checkpoint.get('feature_std', torch.ones(input_size))\n",
    "    \n",
    "    print(f\"‚úÖ Model loaded successfully on {device}\")\n",
    "    return model, feature_mean, feature_std, device\n",
    "\n",
    "# DEBUG: Detailed investigation\n",
    "def debug_data_processing():\n",
    "    \"\"\"Debug why no matches are being processed\"\"\"\n",
    "    \n",
    "    # Check data directory\n",
    "    data_dir = '../data/processed/match_sequences'\n",
    "    if not os.path.exists(data_dir):\n",
    "        print(f\"‚ùå Data directory not found: {data_dir}\")\n",
    "        return\n",
    "    \n",
    "    # Load sequence files\n",
    "    sequence_files = glob(f'{data_dir}/*.csv')\n",
    "    print(f\"üìÅ Found {len(sequence_files)} sequence files\")\n",
    "    \n",
    "    # Debug: Check first few files\n",
    "    print(f\"\\nüîç DEBUGGING FIRST 5 FILES:\")\n",
    "    \n",
    "    for i, seq_file in enumerate(sequence_files[:5]):\n",
    "        print(f\"\\n--- File {i+1}: {os.path.basename(seq_file)} ---\")\n",
    "        \n",
    "        try:\n",
    "            # Try to load CSV\n",
    "            df = pd.read_csv(seq_file)\n",
    "            print(f\"‚úÖ CSV loaded: {df.shape}\")\n",
    "            print(f\"   Columns: {list(df.columns)}\")\n",
    "            \n",
    "            # Check for metadata\n",
    "            meta_file = seq_file.replace('.csv', '_meta.json')\n",
    "            if os.path.exists(meta_file):\n",
    "                with open(meta_file, 'r') as f:\n",
    "                    meta = json.load(f)\n",
    "                print(f\"‚úÖ Metadata loaded: {meta}\")\n",
    "            else:\n",
    "                print(f\"‚ùå No metadata file: {meta_file}\")\n",
    "                \n",
    "            # Check data quality\n",
    "            print(f\"   First few rows:\")\n",
    "            print(df.head(2))\n",
    "            \n",
    "            # Check specific columns we need\n",
    "            required_cols = ['cumulative_runs', 'cumulative_wickets', 'overs_remaining']\n",
    "            missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "            if missing_cols:\n",
    "                print(f\"‚ùå Missing columns: {missing_cols}\")\n",
    "            else:\n",
    "                print(f\"‚úÖ Required columns present\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing file: {e}\")\n",
    "    \n",
    "    print(f\"\\nüîç DETAILED ANALYSIS OF FIRST VALID FILE:\")\n",
    "    \n",
    "    # Find first valid file\n",
    "    for seq_file in sequence_files:\n",
    "        try:\n",
    "            df = pd.read_csv(seq_file)\n",
    "            meta_file = seq_file.replace('.csv', '_meta.json')\n",
    "            \n",
    "            if os.path.exists(meta_file):\n",
    "                with open(meta_file, 'r') as f:\n",
    "                    meta = json.load(f)\n",
    "                \n",
    "                print(f\"\\nüìä File: {os.path.basename(seq_file)}\")\n",
    "                print(f\"   Shape: {df.shape}\")\n",
    "                print(f\"   Columns: {list(df.columns)}\")\n",
    "                print(f\"   Metadata: {meta}\")\n",
    "                \n",
    "                # Check specific values\n",
    "                if len(df) >= 10:\n",
    "                    test_row = df.iloc[9]  # Over 10\n",
    "                    print(f\"\\n   Test row (over 10):\")\n",
    "                    print(f\"   Current runs: {test_row.get('cumulative_runs', 'MISSING')}\")\n",
    "                    print(f\"   Current wickets: {test_row.get('cumulative_wickets', 'MISSING')}\")\n",
    "                    print(f\"   Overs remaining: {test_row.get('overs_remaining', 'MISSING')}\")\n",
    "                    \n",
    "                    # Try DLS calculation\n",
    "                    if all(col in df.columns for col in ['cumulative_runs', 'cumulative_wickets', 'overs_remaining']):\n",
    "                        current_runs = test_row['cumulative_runs']\n",
    "                        current_wickets = test_row['cumulative_wickets']\n",
    "                        overs_remaining = test_row['overs_remaining']\n",
    "                        \n",
    "                        team2_resources = get_dls_resource(overs_remaining, current_wickets)\n",
    "                        final_score = meta.get('final_score', 0)\n",
    "                        \n",
    "                        print(f\"\\n   DLS calculation test:\")\n",
    "                        print(f\"   Team 2 resources: {team2_resources}%\")\n",
    "                        print(f\"   Final score: {final_score}\")\n",
    "                        \n",
    "                        if final_score > 0:\n",
    "                            dls_par = calculate_real_dls_target(final_score, 100.0, team2_resources)\n",
    "                            dls_remaining = max(0, dls_par - current_runs)\n",
    "                            actual_remaining = final_score - current_runs\n",
    "                            \n",
    "                            print(f\"   DLS par score: {dls_par:.1f}\")\n",
    "                            print(f\"   DLS remaining: {dls_remaining:.1f}\")\n",
    "                            print(f\"   Actual remaining: {actual_remaining}\")\n",
    "                            \n",
    "                            # Check if this would pass our filters\n",
    "                            if 0 <= actual_remaining <= 200 and 0 <= dls_remaining <= 300:\n",
    "                                print(f\"   ‚úÖ This match would be VALID for comparison\")\n",
    "                            else:\n",
    "                                print(f\"   ‚ùå This match would be FILTERED OUT\")\n",
    "                                print(f\"       Actual remaining: {actual_remaining} (need 0-200)\")\n",
    "                                print(f\"       DLS remaining: {dls_remaining} (need 0-300)\")\n",
    "                else:\n",
    "                    print(f\"   ‚ùå Too few rows: {len(df)} (need at least 10)\")\n",
    "                \n",
    "                break  # Stop after first valid file\n",
    "                \n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "# Load model first\n",
    "try:\n",
    "    model, feature_mean, feature_std, device = load_trained_model()\n",
    "    \n",
    "    # Run debugging\n",
    "    debug_data_processing()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading model: {e}\")\n",
    "\n",
    "print(f\"\\nüîß SUGGESTIONS TO FIX:\")\n",
    "print(f\"1. Check if column names match expected format\")\n",
    "print(f\"2. Verify metadata files exist and are valid\")\n",
    "print(f\"3. Check if data values are reasonable\")\n",
    "print(f\"4. Ensure sequence files have enough rows\")\n",
    "print(f\"5. Verify feature count matches model expectations\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
